{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Implementing an autoregressive Seq2Seq model\n",
    "\n",
    "### About this notebook\n",
    "\n",
    "This notebook was used in the 50.039 Deep Learning course at the Singapore University of Technology and Design.\n",
    "\n",
    "**Author:** Matthieu DE MARI (matthieu_demari@sutd.edu.sg)\n",
    "\n",
    "**Version:** 1.0 (05/03/2024)\n",
    "\n",
    "**Requirements:**\n",
    "- Python 3 (tested on v3.11.4)\n",
    "- Matplotlib (tested on v3.7.1)\n",
    "- Numpy (tested on v1.24.3)\n",
    "- Torch (tested on v2.0.1+cu118)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date   meantemp   humidity  wind_speed  meanpressure\n",
      "0  2013-01-01  10.000000  84.500000    0.000000   1015.666667\n",
      "1  2013-01-02   7.400000  92.000000    2.980000   1017.800000\n",
      "2  2013-01-03   7.166667  87.000000    4.633333   1018.666667\n",
      "3  2013-01-04   8.666667  71.333333    1.233333   1017.166667\n",
      "4  2013-01-05   6.000000  86.833333    3.700000   1016.500000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Relative path to the CSV\n",
    "csv_path = '../dataset/train/DailyDelhiClimateTrain.csv'\n",
    "\n",
    "# Load the dataset\n",
    "df_train = pd.read_csv(csv_path)\n",
    "\n",
    "# Quick look at the data\n",
    "print(df_train.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>meantemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>meanpressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>84.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1015.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>2.980000</td>\n",
       "      <td>1017.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>7.166667</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>4.633333</td>\n",
       "      <td>1018.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>8.666667</td>\n",
       "      <td>71.333333</td>\n",
       "      <td>1.233333</td>\n",
       "      <td>1017.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-05</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>86.833333</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>1016.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013-01-06</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>82.800000</td>\n",
       "      <td>1.480000</td>\n",
       "      <td>1018.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013-01-07</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>78.600000</td>\n",
       "      <td>6.300000</td>\n",
       "      <td>1020.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>8.857143</td>\n",
       "      <td>63.714286</td>\n",
       "      <td>7.142857</td>\n",
       "      <td>1018.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2013-01-09</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>51.250000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>1017.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2013-01-10</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>1015.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2013-01-11</td>\n",
       "      <td>15.714286</td>\n",
       "      <td>51.285714</td>\n",
       "      <td>10.571429</td>\n",
       "      <td>1016.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2013-01-12</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>13.228571</td>\n",
       "      <td>1015.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2013-01-13</td>\n",
       "      <td>15.833333</td>\n",
       "      <td>75.166667</td>\n",
       "      <td>4.633333</td>\n",
       "      <td>1013.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2013-01-14</td>\n",
       "      <td>12.833333</td>\n",
       "      <td>88.166667</td>\n",
       "      <td>0.616667</td>\n",
       "      <td>1015.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2013-01-15</td>\n",
       "      <td>14.714286</td>\n",
       "      <td>71.857143</td>\n",
       "      <td>0.528571</td>\n",
       "      <td>1015.857143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date   meantemp   humidity  wind_speed  meanpressure\n",
       "0   2013-01-01  10.000000  84.500000    0.000000   1015.666667\n",
       "1   2013-01-02   7.400000  92.000000    2.980000   1017.800000\n",
       "2   2013-01-03   7.166667  87.000000    4.633333   1018.666667\n",
       "3   2013-01-04   8.666667  71.333333    1.233333   1017.166667\n",
       "4   2013-01-05   6.000000  86.833333    3.700000   1016.500000\n",
       "5   2013-01-06   7.000000  82.800000    1.480000   1018.000000\n",
       "6   2013-01-07   7.000000  78.600000    6.300000   1020.000000\n",
       "7   2013-01-08   8.857143  63.714286    7.142857   1018.714286\n",
       "8   2013-01-09  14.000000  51.250000   12.500000   1017.000000\n",
       "9   2013-01-10  11.000000  62.000000    7.400000   1015.666667\n",
       "10  2013-01-11  15.714286  51.285714   10.571429   1016.142857\n",
       "11  2013-01-12  14.000000  74.000000   13.228571   1015.571429\n",
       "12  2013-01-13  15.833333  75.166667    4.633333   1013.333333\n",
       "13  2013-01-14  12.833333  88.166667    0.616667   1015.166667\n",
       "14  2013-01-15  14.714286  71.857143    0.528571   1015.857143"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([64, 90, 4])\n",
      "Output shape: torch.Size([64, 90, 4])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Load the multivariate CSV\n",
    "df = pd.read_csv('../dataset/train/DailyDelhiClimateTrain.csv')\n",
    "\n",
    "# Drop the 'date' column and convert the rest to numpy\n",
    "data = df.drop(columns=['date']).values.astype(np.float32)\n",
    "\n",
    "# Sequence and future steps\n",
    "seq_length = 90\n",
    "future_steps = 90  # 5 steps\n",
    "\n",
    "torch.set_printoptions(precision=4, sci_mode=False)\n",
    "\n",
    "# Custom Dataset\n",
    "class MultivariateTimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data, seq_length, future_steps):\n",
    "        self.data = data\n",
    "        self.seq_length = seq_length\n",
    "        self.future_steps = future_steps\n",
    "\n",
    "    def __len__(self):\n",
    "        # Must have enough room for input + future\n",
    "        return len(self.data) - self.seq_length - self.future_steps + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx : idx + self.seq_length]\n",
    "        y = self.data[idx + self.seq_length : idx + self.seq_length + self.future_steps]\n",
    "        return torch.tensor(x).float(), torch.tensor(y).float()\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = MultivariateTimeSeriesDataset(data, seq_length, future_steps)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Visualize a sample\n",
    "sample = next(iter(dataloader))\n",
    "input_sample, output_sample = sample\n",
    "print(\"Input shape:\", input_sample.shape)   # [64, 10, 4]\n",
    "print(\"Output shape:\", output_sample.shape) # [64, 5, 4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[   10.0000,    84.5000,     0.0000,  1015.6667],\n",
       "         [    7.4000,    92.0000,     2.9800,  1017.8000],\n",
       "         [    7.1667,    87.0000,     4.6333,  1018.6667],\n",
       "         [    8.6667,    71.3333,     1.2333,  1017.1667],\n",
       "         [    6.0000,    86.8333,     3.7000,  1016.5000],\n",
       "         [    7.0000,    82.8000,     1.4800,  1018.0000],\n",
       "         [    7.0000,    78.6000,     6.3000,  1020.0000],\n",
       "         [    8.8571,    63.7143,     7.1429,  1018.7143],\n",
       "         [   14.0000,    51.2500,    12.5000,  1017.0000],\n",
       "         [   11.0000,    62.0000,     7.4000,  1015.6667],\n",
       "         [   15.7143,    51.2857,    10.5714,  1016.1429],\n",
       "         [   14.0000,    74.0000,    13.2286,  1015.5714],\n",
       "         [   15.8333,    75.1667,     4.6333,  1013.3333],\n",
       "         [   12.8333,    88.1667,     0.6167,  1015.1667],\n",
       "         [   14.7143,    71.8571,     0.5286,  1015.8571],\n",
       "         [   13.8333,    86.6667,     0.0000,  1016.6667],\n",
       "         [   16.5000,    80.8333,     5.2500,  1015.8333],\n",
       "         [   13.8333,    92.1667,     8.9500,  1014.5000],\n",
       "         [   12.5000,    76.6667,     5.8833,  1021.6667],\n",
       "         [   11.2857,    75.2857,     8.4714,  1020.2857],\n",
       "         [   11.2000,    77.0000,     2.2200,  1021.0000],\n",
       "         [    9.5000,    79.6667,     3.0833,  1021.8000],\n",
       "         [   14.0000,    60.1667,     4.0167,  1020.5000],\n",
       "         [   13.8333,    60.6667,     6.1667,  1020.5000],\n",
       "         [   12.2500,    67.0000,     5.5500,  1020.7500],\n",
       "         [   12.6667,    64.1667,     6.8000,  1019.6667],\n",
       "         [   12.8571,    65.5714,     5.5571,  1018.1429],\n",
       "         [   14.8333,    56.0000,     3.7000,  1017.8333],\n",
       "         [   14.1250,    65.5000,     3.2375,  1016.6250],\n",
       "         [   14.7143,    70.4286,     1.0571,  1017.8571],\n",
       "         [   16.2000,    65.6000,     2.9600,  1018.4000],\n",
       "         [   16.0000,    73.0000,     2.2200,  1016.0000],\n",
       "         [   16.2857,    77.5714,     1.3286,  1017.1429],\n",
       "         [   18.0000,    65.5714,     1.8571,  1015.2857],\n",
       "         [   17.4286,    74.2857,    11.1143,  1014.5714],\n",
       "         [   16.6250,    92.3750,     9.7250,  1016.3750],\n",
       "         [   16.6667,    71.3333,     8.6333,  1018.6667],\n",
       "         [   15.6000,    59.4000,    10.7400,  1018.6000],\n",
       "         [   14.0000,    70.4286,     9.2571,  1017.1429],\n",
       "         [   15.4286,    61.2857,     9.2571,  1016.8571],\n",
       "         [   15.2500,    71.5000,     3.4750,  1017.1250],\n",
       "         [   15.8750,    70.5000,     5.3250,  1016.5000],\n",
       "         [   15.3333,    70.3333,     7.4167,  1017.5000],\n",
       "         [   16.2857,    70.1429,     6.0857,  1016.0000],\n",
       "         [   17.3333,    63.8333,     4.3333,  1014.1667],\n",
       "         [   19.1667,    65.3333,    10.1833,  1011.6667],\n",
       "         [   14.4286,    92.7143,     8.4857,  1008.0000],\n",
       "         [   13.6667,    90.0000,     0.0000,  1012.6667],\n",
       "         [   15.6000,    78.4000,    12.2200,  1016.2000],\n",
       "         [   15.8571,    82.0000,     5.8143,  1015.7143],\n",
       "         [   17.7143,    74.7143,     5.8143,  1017.0000],\n",
       "         [   20.0000,    67.2857,     6.6143,  1015.4286],\n",
       "         [   20.5000,    65.6250,    10.8750,  1016.0000],\n",
       "         [   17.4286,    74.8571,     9.2571,  1017.0000],\n",
       "         [   16.8571,    78.8571,     7.4000,  1018.8571],\n",
       "         [   16.8750,    72.8750,     4.6375,  1018.2500],\n",
       "         [   17.8571,    70.0000,    17.5875,  1015.1429],\n",
       "         [   20.8000,    57.2000,     6.6600,  1015.2000],\n",
       "         [   19.4286,    52.8571,    12.9571,  1017.4286],\n",
       "         [   17.3333,    49.3333,    24.0667,  1016.3333],\n",
       "         [   19.0000,    54.0000,    15.7250,  1016.2500],\n",
       "         [   19.3333,    62.8333,     8.6333,  1016.1667],\n",
       "         [   17.6000,    71.0000,     5.5600,  1015.8000],\n",
       "         [   20.8750,    61.8750,     4.1625,  1016.3750],\n",
       "         [   20.8571,    65.2857,     6.8714,  1015.7143],\n",
       "         [   23.4286,    57.1429,     8.7286,  1015.2857],\n",
       "         [   24.1667,    44.8333,     7.1000,  1014.8333],\n",
       "         [   25.4286,    49.7143,     5.2857,  1009.2857],\n",
       "         [   23.1429,    57.5714,     4.2286,  1008.0000],\n",
       "         [   24.0000,    66.3333,     0.9333,  1011.1667],\n",
       "         [   23.5000,    62.5000,     4.9333,  1011.5000],\n",
       "         [   21.5000,    70.5000,     5.5500,  1009.0000],\n",
       "         [   22.3333,    61.1667,    12.0333,  1013.1667],\n",
       "         [   24.1667,    45.8333,     7.7167,  1016.1667],\n",
       "         [   20.3333,    67.6667,     3.7000,  1016.1667],\n",
       "         [   22.6667,    58.6667,     8.9500,  1015.0000],\n",
       "         [   23.4286,    58.1429,    17.4571,  1009.4286],\n",
       "         [   22.5000,    73.6667,    10.4833,  1011.0000],\n",
       "         [   29.1667,    36.3333,     6.8000,  1009.5000],\n",
       "         [   23.8333,    58.5000,    10.5000,  1008.3333],\n",
       "         [   25.2500,    50.2500,     9.7125,  1006.3750],\n",
       "         [   27.3750,    50.1250,     9.9500,  1007.6250],\n",
       "         [   27.0000,    48.7500,    10.8875,  1010.2500],\n",
       "         [   23.5000,    45.5000,    15.9625,  1010.6250],\n",
       "         [   24.1429,    44.5714,    12.9571,  1008.8571],\n",
       "         [   21.0000,    62.0000,     1.8500,  1009.0000],\n",
       "         [   22.4286,    62.7143,     7.4143,  1009.5714],\n",
       "         [   21.2500,    70.3750,     5.5500,  1009.7500],\n",
       "         [   23.5000,    54.7500,    11.1125,  1008.6250],\n",
       "         [   23.2000,    58.0000,     6.6600,  1008.6000]]),\n",
       " tensor([[  25.3750,   45.5000,    4.4000, 1008.5000],\n",
       "         [  25.1667,   51.0000,    8.6500, 1009.5000],\n",
       "         [  26.2000,   45.6000,    8.1400, 1009.0000],\n",
       "         [  24.6000,   41.8000,   11.1200, 1007.8000],\n",
       "         [  25.6000,   31.0000,   15.5600, 1007.0000],\n",
       "         [  25.8571,   29.8571,   11.9000, 1006.1429],\n",
       "         [  29.1429,   23.2857,   10.3143, 1005.0000],\n",
       "         [  28.7143,   33.8571,    5.3000, 1006.0000],\n",
       "         [  30.1667,   30.5000,    8.6500, 1005.3333],\n",
       "         [  30.0000,   28.0000,    6.1000, 1006.7143],\n",
       "         [  30.0000,   24.2000,    7.7800, 1006.4000],\n",
       "         [  28.8571,   32.5714,    6.3429, 1007.5714],\n",
       "         [  30.2000,   29.2000,   10.0000, 1008.4000],\n",
       "         [  28.2500,   39.3750,    6.4875, 1007.0000],\n",
       "         [  28.2500,   41.3750,    6.2500, 1003.8750],\n",
       "         [  32.1250,   24.6250,   10.4250, 1000.0000],\n",
       "         [  29.2000,   24.2000,    6.6600, 1002.2000],\n",
       "         [  30.2857,   30.2857,    4.7571, 1002.8571],\n",
       "         [  28.2857,   31.2857,    3.9714, 1002.5714],\n",
       "         [  30.6250,   29.0000,    7.6375, 1003.3750],\n",
       "         [  27.6667,   38.6667,   13.8833, 1006.8333],\n",
       "         [  27.3750,   45.3750,    7.6500, 1010.0000],\n",
       "         [  28.6250,   44.1250,    4.6250, 1009.8750],\n",
       "         [  30.2857,   41.7143,    2.1143, 1008.5714],\n",
       "         [  31.1429,   38.2857,    3.7000, 1007.7143],\n",
       "         [  29.8750,   45.8750,    6.7125, 1008.3750],\n",
       "         [  31.1429,   31.4286,   13.4857, 1007.0000],\n",
       "         [  30.5714,   28.0000,   12.9714, 1005.4286],\n",
       "         [  32.1250,   26.3750,    7.8750, 1004.8750],\n",
       "         [  31.1429,   32.0000,    7.9286, 1004.8571],\n",
       "         [  31.8571,   15.8571,   12.6857, 1002.8333],\n",
       "         [  29.8333,   22.1667,   11.4333, 1001.2000],\n",
       "         [  28.5714,   31.5714,    9.0000,  999.4286],\n",
       "         [  32.8571,   31.4286,    2.9143,  999.0000],\n",
       "         [  32.6250,   31.1250,    3.0125, 1000.6250],\n",
       "         [  32.7500,   39.2500,    3.7000, 1001.6250],\n",
       "         [  32.8750,   33.2500,    7.1750, 1002.0000],\n",
       "         [  34.5000,   23.0000,    9.2500, 1001.1667],\n",
       "         [  34.2857,   26.0000,    8.9857, 1000.8571],\n",
       "         [  34.0000,   27.7143,    9.5286, 1000.1429],\n",
       "         [  30.7500,   30.3750,   14.8125,  999.8750],\n",
       "         [  29.8571,   40.1429,    5.8286, 1003.7143],\n",
       "         [  31.7143,   34.0000,    3.9714, 1003.5714],\n",
       "         [  32.2857,   34.2857,    4.7714, 1001.5714],\n",
       "         [  33.0000,   33.0000,    3.2375,  999.8571],\n",
       "         [  33.0000,   34.7500,    7.1750,  998.5000],\n",
       "         [  32.8333,   28.1667,    9.8667, 1000.3333],\n",
       "         [  31.4000,   42.2000,   12.9667,  999.0000],\n",
       "         [  35.3333,   22.3333,   15.7500,  999.6667],\n",
       "         [  36.4000,   24.2000,    7.4000,  998.4000],\n",
       "         [  36.0000,   19.0000,   11.3714,  998.6667],\n",
       "         [  36.7500,   22.1250,   17.5875,  998.6250],\n",
       "         [  37.5000,   23.3333,   13.5667,  997.1667],\n",
       "         [  38.4286,   27.4286,   11.3857,  996.4286],\n",
       "         [  38.7143,   22.4286,   10.3143,  998.1429],\n",
       "         [  37.8000,   21.2000,   10.7400,  998.2000],\n",
       "         [  35.8571,   31.5714,    8.7286,  999.1429],\n",
       "         [  35.3333,   29.0000,    8.3333, 1000.1667],\n",
       "         [  34.1429,   27.8571,    5.5571,  999.4286],\n",
       "         [  32.2000,   28.2000,    5.5600,  999.6000],\n",
       "         [  33.6250,   40.1250,   10.6375,  998.7143],\n",
       "         [  32.0000,   54.0000,   13.4375,  998.7500],\n",
       "         [  32.4000,   56.6000,   14.2000, 1001.0000],\n",
       "         [  35.6000,   47.0000,   12.2400,  999.6000],\n",
       "         [  35.8571,   42.5714,    5.0286,  999.8571],\n",
       "         [  37.1667,   36.5000,    9.8667,  998.0000],\n",
       "         [  31.2857,   61.7143,   10.0429,  997.2857],\n",
       "         [  34.0000,   49.2500,    7.4125,  998.0000],\n",
       "         [  34.2000,   57.4000,   13.3400,  997.0000],\n",
       "         [  36.1667,   40.0000,   11.4167,  995.1667],\n",
       "         [  36.6250,   42.7500,    8.1000,  995.1250],\n",
       "         [  30.1667,   61.6667,   16.3500, 1000.0000],\n",
       "         [  34.1429,   54.1429,    7.4143,  998.0000],\n",
       "         [  29.8333,   68.6667,    9.8667,  998.6667],\n",
       "         [  30.1429,   68.1429,    7.9429,  997.4286],\n",
       "         [  30.7143,   65.0000,   13.2286,  997.8571],\n",
       "         [  27.0000,   88.8571,    8.4857,  996.4286],\n",
       "         [  26.8750,   87.3750,    8.3375,  994.7500],\n",
       "         [  28.4000,   83.6000,    5.1800,  996.4000],\n",
       "         [  29.8571,   72.8571,    4.2286,  999.0000],\n",
       "         [  33.0000,   52.7143,    4.7714,  997.1667],\n",
       "         [  34.8333,   47.3333,    5.8667,  995.3333],\n",
       "         [  35.6000,   39.4000,   10.7400,  996.2000],\n",
       "         [  35.1667,   53.0000,    8.3500,  995.6667],\n",
       "         [  33.1429,   55.0000,   13.2286,  996.2857],\n",
       "         [  30.5714,   70.4286,   11.1143,  999.1667],\n",
       "         [  30.6667,   71.5000,    6.4833,  999.0000],\n",
       "         [  31.4286,   61.8571,    7.9571,  996.7143],\n",
       "         [  31.5000,   64.2500,    8.8125,  996.0000],\n",
       "         [  33.2500,   57.0000,   13.8750,  995.2500]]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and CUDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our encoder model\n",
    "\n",
    "The EncoderRNN below processes input sequences through an LSTM. It is designed to capture the temporal dependencies in the data.\n",
    "Only the final hidden states are returned, encapsulating the learned representation of the entire sequence. This encoder can be used in sequence-to-sequence models, where its hidden state initializes the decoder to generate outputs based on the input sequence.\n",
    "\n",
    "It uses several layers of LSTM and possibly dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# Numpy\n",
    "import numpy as np\n",
    "# Torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers = 1, dropout = 0.0):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn = nn.LSTM(input_size, hidden_size, num_layers = num_layers, \n",
    "                           dropout = dropout if num_layers > 1 else 0.0, \n",
    "                           batch_first = True)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        # For this encoder, we ignore the outputs if we only need the final hidden state(s)\n",
    "        outputs, hidden = self.rnn(input_seq)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our decoder model\n",
    "\n",
    "The DecoderRNN class is a PyTorch module designed to act as the decoder in a sequence-to-sequence architecture. It processes input sequences using an LSTM and then maps the LSTM outputs to the desired output space with a linear layer. It returns both the predicted output and the updated hidden state, making it suitable for sequential decoding in sequence-to-sequence tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers = 1, dropout = 0.0):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn = nn.LSTM(input_size, hidden_size, num_layers = num_layers, \n",
    "                           dropout = dropout if num_layers > 1 else 0.0, \n",
    "                           batch_first = True)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input_seq, hidden):\n",
    "        # Get the raw output from the RNN along with updated hidden state(s)\n",
    "        output, hidden = self.rnn(input_seq, hidden)\n",
    "        output = self.linear(output)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our Seq2Seq model\n",
    "\n",
    "Assembling our encoder and decoder classes from earlier, the Seq2Seq class implements a sequence-to-sequence model using an encoder-decoder architecture. The encoder processes the input sequence to produce a final hidden state, which is then used as the starting point for the memory vector of the decoder. The decoder is then responsible for generating the output sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers = 1, dropout = 0.0):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.encoder = EncoderRNN(input_size, hidden_size, num_layers, dropout)\n",
    "        self.decoder = DecoderRNN(input_size, hidden_size, output_size, num_layers, dropout)\n",
    "\n",
    "    def forward(self, input_seq, target_seq_length):\n",
    "        # Encoder part: obtain the hidden state from the encoder.\n",
    "        # Returns a tuple (hidden_state, cell_state)\n",
    "        encoder_hidden = self.encoder(input_seq)\n",
    "       \n",
    "        # Prepare a non-autoregressive decoder input.\n",
    "        # Use the last time step from input_seq as the initial decoder input.\n",
    "        # For instance, use a fixed start token or learnable embeddings for each time step.\n",
    "       \n",
    "        # Here we simply repeat the last time step for all target positions.\n",
    "        decoder_input = input_seq[:, -1].unsqueeze(1).repeat(1, target_seq_length, 1)\n",
    "        \n",
    "        # Then, directly process the entire sequence in the decoder.\n",
    "        decoder_output, decoder_hidden = self.decoder(decoder_input, encoder_hidden)\n",
    "\n",
    "        return decoder_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A simple trainer function\n",
    "\n",
    "Our trainer function will be kept simple and will be similar to many other things we have seen this term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available: True\n"
     ]
    }
   ],
   "source": [
    "# Define device for torch\n",
    "use_cuda = True\n",
    "print(\"CUDA is available:\", torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_seq2seq(model, dataloader, num_epochs, learning_rate):\n",
    "    model.to(device)               # Move model to device (GPU or CPU)\n",
    "    model.train()                  # Set the model to training mode\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "\n",
    "        for input_seq, target_seq in dataloader:\n",
    "            input_seq = input_seq.to(device)         # Move input to device\n",
    "            target_seq = target_seq.to(device)       # Move target to device\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output_seq = model(input_seq, future_steps)\n",
    "            loss = criterion(output_seq, target_seq)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss / len(dataloader)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And it trains!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 261369.8474702381\n",
      "Epoch 2/100, Loss: 256757.05208333334\n",
      "Epoch 3/100, Loss: 255564.06473214287\n",
      "Epoch 4/100, Loss: 249874.39880952382\n",
      "Epoch 5/100, Loss: 246479.10119047618\n",
      "Epoch 6/100, Loss: 243313.09523809524\n",
      "Epoch 7/100, Loss: 240277.11979166666\n",
      "Epoch 8/100, Loss: 237211.49776785713\n",
      "Epoch 9/100, Loss: 234273.42038690476\n",
      "Epoch 10/100, Loss: 233732.70238095237\n",
      "Epoch 11/100, Loss: 230564.07663690476\n",
      "Epoch 12/100, Loss: 225379.2619047619\n",
      "Epoch 13/100, Loss: 224846.56473214287\n",
      "Epoch 14/100, Loss: 219790.05357142858\n",
      "Epoch 15/100, Loss: 217001.29836309524\n",
      "Epoch 16/100, Loss: 214305.04761904763\n",
      "Epoch 17/100, Loss: 211606.33854166666\n",
      "Epoch 18/100, Loss: 208852.62723214287\n",
      "Epoch 19/100, Loss: 206110.8087797619\n",
      "Epoch 20/100, Loss: 205871.48214285713\n",
      "Epoch 21/100, Loss: 200968.93675595237\n",
      "Epoch 22/100, Loss: 200538.54910714287\n",
      "Epoch 23/100, Loss: 195887.31101190476\n",
      "Epoch 24/100, Loss: 195578.1525297619\n",
      "Epoch 25/100, Loss: 190681.34449404763\n",
      "Epoch 26/100, Loss: 188466.84970238095\n",
      "Epoch 27/100, Loss: 185800.09895833334\n",
      "Epoch 28/100, Loss: 183366.8556547619\n",
      "Epoch 29/100, Loss: 181082.57738095237\n",
      "Epoch 30/100, Loss: 178592.31994047618\n",
      "Epoch 31/100, Loss: 176211.71130952382\n",
      "Epoch 32/100, Loss: 176391.3005952381\n",
      "Epoch 33/100, Loss: 171571.98139880953\n",
      "Epoch 34/100, Loss: 169354.40848214287\n",
      "Epoch 35/100, Loss: 166864.09672619047\n",
      "Epoch 36/100, Loss: 167014.74330357142\n",
      "Epoch 37/100, Loss: 162435.66294642858\n",
      "Epoch 38/100, Loss: 160456.36904761905\n",
      "Epoch 39/100, Loss: 158250.8392857143\n",
      "Epoch 40/100, Loss: 155990.98139880953\n",
      "Epoch 41/100, Loss: 156309.09598214287\n",
      "Epoch 42/100, Loss: 151878.5111607143\n",
      "Epoch 43/100, Loss: 149627.14360119047\n",
      "Epoch 44/100, Loss: 147707.85639880953\n",
      "Epoch 45/100, Loss: 145566.29910714287\n",
      "Epoch 46/100, Loss: 143576.20572916666\n",
      "Epoch 47/100, Loss: 141738.94494047618\n",
      "Epoch 48/100, Loss: 139658.26525297618\n",
      "Epoch 49/100, Loss: 139986.24107142858\n",
      "Epoch 50/100, Loss: 135797.1443452381\n",
      "Epoch 51/100, Loss: 133927.11607142858\n",
      "Epoch 52/100, Loss: 131970.546875\n",
      "Epoch 53/100, Loss: 130110.93340773809\n",
      "Epoch 54/100, Loss: 128276.26488095238\n",
      "Epoch 55/100, Loss: 126372.01860119047\n",
      "Epoch 56/100, Loss: 124587.49516369047\n",
      "Epoch 57/100, Loss: 122844.97470238095\n",
      "Epoch 58/100, Loss: 121159.93340773809\n",
      "Epoch 59/100, Loss: 119312.03459821429\n",
      "Epoch 60/100, Loss: 117545.65215773809\n",
      "Epoch 61/100, Loss: 115906.68377976191\n",
      "Epoch 62/100, Loss: 114169.91220238095\n",
      "Epoch 63/100, Loss: 112631.71056547618\n",
      "Epoch 64/100, Loss: 113146.70424107143\n",
      "Epoch 65/100, Loss: 109310.66778273809\n",
      "Epoch 66/100, Loss: 107747.97730654762\n",
      "Epoch 67/100, Loss: 106183.62090773809\n",
      "Epoch 68/100, Loss: 104557.0703125\n",
      "Epoch 69/100, Loss: 102927.51934523809\n",
      "Epoch 70/100, Loss: 101433.65104166667\n",
      "Epoch 71/100, Loss: 99854.38020833333\n",
      "Epoch 72/100, Loss: 98440.1796875\n",
      "Epoch 73/100, Loss: 96858.84263392857\n",
      "Epoch 74/100, Loss: 97664.74293154762\n",
      "Epoch 75/100, Loss: 93942.92150297618\n",
      "Epoch 76/100, Loss: 94783.92113095238\n",
      "Epoch 77/100, Loss: 91103.02976190476\n",
      "Epoch 78/100, Loss: 89771.71912202382\n",
      "Epoch 79/100, Loss: 88376.84598214286\n",
      "Epoch 80/100, Loss: 87059.34747023809\n",
      "Epoch 81/100, Loss: 85601.36830357143\n",
      "Epoch 82/100, Loss: 84314.87351190476\n",
      "Epoch 83/100, Loss: 85119.50744047618\n",
      "Epoch 84/100, Loss: 81628.37388392857\n",
      "Epoch 85/100, Loss: 80423.37351190476\n",
      "Epoch 86/100, Loss: 79122.88430059524\n",
      "Epoch 87/100, Loss: 77952.62351190476\n",
      "Epoch 88/100, Loss: 76629.44568452382\n",
      "Epoch 89/100, Loss: 75362.92987351191\n",
      "Epoch 90/100, Loss: 74122.05505952382\n",
      "Epoch 91/100, Loss: 72971.23232886905\n",
      "Epoch 92/100, Loss: 73965.96056547618\n",
      "Epoch 93/100, Loss: 70681.90104166667\n",
      "Epoch 94/100, Loss: 69518.00260416667\n",
      "Epoch 95/100, Loss: 68409.90178571429\n",
      "Epoch 96/100, Loss: 67228.87909226191\n",
      "Epoch 97/100, Loss: 66088.12723214286\n",
      "Epoch 98/100, Loss: 65120.615885416664\n",
      "Epoch 99/100, Loss: 63936.158482142855\n",
      "Epoch 100/100, Loss: 63027.786458333336\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "input_size = 4 \n",
    "hidden_size = 300\n",
    "output_size = 4\n",
    "learning_rate = 0.001\n",
    "num_epochs = 100\n",
    "num_layers = 3\n",
    "dropout_rate = 0.1\n",
    "\n",
    "# Initialize Seq2Seq Model\n",
    "seq2seq_model = Seq2Seq(input_size, hidden_size, output_size, num_layers, dropout_rate)\n",
    "\n",
    "# Train the model\n",
    "train_seq2seq(seq2seq_model, dataloader, num_epochs, learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A bit of evaluation to confirm\n",
    "\n",
    "The code below will simply extract one sample from the dataset and confirm that our model predicts correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date   meantemp   humidity  wind_speed  meanpressure\n",
      "0  2017-01-01  15.913043  85.869565    2.743478     59.000000\n",
      "1  2017-01-02  18.500000  77.222222    2.894444   1018.277778\n",
      "2  2017-01-03  17.111111  81.888889    4.016667   1018.333333\n",
      "3  2017-01-04  18.700000  70.050000    4.545000   1015.700000\n",
      "4  2017-01-05  18.388889  74.944444    3.300000   1014.333333\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Relative path to the CSV\n",
    "csv_path = '../dataset/test/DailyDelhiClimateTest.csv'\n",
    "\n",
    "# Load the dataset\n",
    "df_test = pd.read_csv(csv_path)\n",
    "\n",
    "# Quick look at the data\n",
    "print(df_test.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>meantemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>meanpressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>15.913043</td>\n",
       "      <td>85.869565</td>\n",
       "      <td>2.743478</td>\n",
       "      <td>59.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>77.222222</td>\n",
       "      <td>2.894444</td>\n",
       "      <td>1018.277778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>17.111111</td>\n",
       "      <td>81.888889</td>\n",
       "      <td>4.016667</td>\n",
       "      <td>1018.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>18.700000</td>\n",
       "      <td>70.050000</td>\n",
       "      <td>4.545000</td>\n",
       "      <td>1015.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>18.388889</td>\n",
       "      <td>74.944444</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>1014.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>2017-04-20</td>\n",
       "      <td>34.500000</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>5.562500</td>\n",
       "      <td>998.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>2017-04-21</td>\n",
       "      <td>34.250000</td>\n",
       "      <td>39.375000</td>\n",
       "      <td>6.962500</td>\n",
       "      <td>999.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>2017-04-22</td>\n",
       "      <td>32.900000</td>\n",
       "      <td>40.900000</td>\n",
       "      <td>8.890000</td>\n",
       "      <td>1001.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>32.875000</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>9.962500</td>\n",
       "      <td>1002.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>2017-04-24</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>27.142857</td>\n",
       "      <td>12.157143</td>\n",
       "      <td>1004.142857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date   meantemp   humidity  wind_speed  meanpressure\n",
       "0    2017-01-01  15.913043  85.869565    2.743478     59.000000\n",
       "1    2017-01-02  18.500000  77.222222    2.894444   1018.277778\n",
       "2    2017-01-03  17.111111  81.888889    4.016667   1018.333333\n",
       "3    2017-01-04  18.700000  70.050000    4.545000   1015.700000\n",
       "4    2017-01-05  18.388889  74.944444    3.300000   1014.333333\n",
       "..          ...        ...        ...         ...           ...\n",
       "109  2017-04-20  34.500000  27.500000    5.562500    998.625000\n",
       "110  2017-04-21  34.250000  39.375000    6.962500    999.875000\n",
       "111  2017-04-22  32.900000  40.900000    8.890000   1001.600000\n",
       "112  2017-04-23  32.875000  27.500000    9.962500   1002.125000\n",
       "113  2017-04-24  32.000000  27.142857   12.157143   1004.142857\n",
       "\n",
       "[114 rows x 5 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meantemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>meanpressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>114.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>114.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>21.713079</td>\n",
       "      <td>56.258362</td>\n",
       "      <td>8.143924</td>\n",
       "      <td>1004.035090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.360072</td>\n",
       "      <td>19.068083</td>\n",
       "      <td>3.588049</td>\n",
       "      <td>89.474692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>17.750000</td>\n",
       "      <td>1.387500</td>\n",
       "      <td>59.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>16.437198</td>\n",
       "      <td>39.625000</td>\n",
       "      <td>5.563542</td>\n",
       "      <td>1007.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>19.875000</td>\n",
       "      <td>57.750000</td>\n",
       "      <td>8.069444</td>\n",
       "      <td>1012.739316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>27.705357</td>\n",
       "      <td>71.902778</td>\n",
       "      <td>10.068750</td>\n",
       "      <td>1016.739583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>34.500000</td>\n",
       "      <td>95.833333</td>\n",
       "      <td>19.314286</td>\n",
       "      <td>1022.809524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         meantemp    humidity  wind_speed  meanpressure\n",
       "count  114.000000  114.000000  114.000000    114.000000\n",
       "mean    21.713079   56.258362    8.143924   1004.035090\n",
       "std      6.360072   19.068083    3.588049     89.474692\n",
       "min     11.000000   17.750000    1.387500     59.000000\n",
       "25%     16.437198   39.625000    5.563542   1007.437500\n",
       "50%     19.875000   57.750000    8.069444   1012.739316\n",
       "75%     27.705357   71.902778   10.068750   1016.739583\n",
       "max     34.500000   95.833333   19.314286   1022.809524"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  15.913043 ,   85.86957  ,    2.7434783,   59.       ],\n",
       "       [  18.5      ,   77.22222  ,    2.8944445, 1018.2778   ],\n",
       "       [  17.11111  ,   81.888885 ,    4.016667 , 1018.3333   ],\n",
       "       [  18.7      ,   70.05     ,    4.545    , 1015.7      ],\n",
       "       [  18.38889  ,   74.94444  ,    3.3      , 1014.3333   ],\n",
       "       [  19.318182 ,   79.318184 ,    8.681818 , 1011.7727   ],\n",
       "       [  14.708333 ,   95.833336 ,   10.041667 , 1011.375    ],\n",
       "       [  15.684211 ,   83.52631  ,    1.95     , 1015.55     ],\n",
       "       [  14.571428 ,   80.809525 ,    6.542857 , 1015.9524   ],\n",
       "       [  12.111111 ,   71.94444  ,    9.361111 , 1016.8889   ],\n",
       "       [  11.       ,   72.111115 ,    9.7722225, 1016.7778   ],\n",
       "       [  11.789474 ,   74.57895  ,    6.6263156, 1016.3684   ],\n",
       "       [  13.235294 ,   67.05882  ,    6.435294 , 1017.5294   ],\n",
       "       [  13.2      ,   74.28     ,    5.276    , 1018.84     ],\n",
       "       [  16.434782 ,   72.565216 ,    3.6304348, 1018.13043  ],\n",
       "       [  14.65     ,   78.45     ,   10.38     , 1017.15     ],\n",
       "       [  11.722222 ,   84.44444  ,    8.038889 , 1018.3889   ],\n",
       "       [  13.041667 ,   78.333336 ,    6.0291667, 1021.9583   ],\n",
       "       [  14.619047 ,   75.14286  ,   10.338096 , 1022.8095   ],\n",
       "       [  15.263158 ,   66.47369  ,   11.2263155, 1021.7895   ],\n",
       "       [  15.391304 ,   70.86957  ,   13.695652 , 1020.4783   ],\n",
       "       [  18.44     ,   76.24     ,    5.868    , 1021.04     ],\n",
       "       [  18.117647 ,   76.       ,    6.752941 , 1019.82355  ],\n",
       "       [  18.347826 ,   68.13043  ,    3.3913043, 1018.86957  ],\n",
       "       [  21.       ,   69.96     ,    8.756    , 1018.4      ],\n",
       "       [  16.178572 ,   91.64286  ,    8.467857 , 1017.7857   ],\n",
       "       [  16.5      ,   77.041664 ,   14.358334 , 1018.125    ],\n",
       "       [  14.863636 ,   82.77273  ,    9.690909 , 1019.63635  ],\n",
       "       [  15.666667 ,   81.77778  ,   10.294444 , 1017.3889   ],\n",
       "       [  16.444445 ,   77.55556  ,    4.322222 , 1015.8333   ],\n",
       "       [  16.125    ,   76.       ,    4.625    , 1015.5      ],\n",
       "       [  15.25     ,   78.625    ,    5.1      , 1017.5      ],\n",
       "       [  17.09091  ,   66.545456 ,    3.0272727, 1018.9091   ],\n",
       "       [  15.636364 ,   78.181816 ,    1.8545455, 1017.7273   ],\n",
       "       [  18.7      ,   77.6      ,    9.82     , 1014.4      ],\n",
       "       [  18.631578 ,   77.63158  ,    8.1      , 1014.2105   ],\n",
       "       [  16.88889  ,   69.666664 ,    9.044444 , 1016.       ],\n",
       "       [  15.125    ,   63.75     ,    7.6375   , 1016.125    ],\n",
       "       [  15.7      ,   68.4      ,    4.08     , 1015.6      ],\n",
       "       [  15.375    ,   68.375    ,    7.875    , 1016.375    ],\n",
       "       [  14.666667 ,   71.77778  ,    9.066667 , 1015.6667   ],\n",
       "       [  15.625    ,   64.       ,    3.95     , 1016.625    ],\n",
       "       [  16.25     ,   70.375    ,    1.625    , 1019.625    ],\n",
       "       [  16.333334 ,   67.       ,    6.3777776, 1021.55554  ],\n",
       "       [  16.875    ,   65.5      ,    6.9625   , 1021.375    ],\n",
       "       [  17.571428 ,   67.71429  ,    5.5571427, 1020.5714   ],\n",
       "       [  20.25     ,   56.75     ,   10.4375   , 1017.625    ],\n",
       "       [  21.3      ,   64.4      ,    9.28     , 1016.5      ],\n",
       "       [  21.125    ,   70.75     ,    6.25     , 1016.25     ],\n",
       "       [  22.363636 ,   66.09091  ,    6.0545454, 1013.       ],\n",
       "       [  23.375    ,   60.125    ,    6.9375   , 1005.375    ],\n",
       "       [  21.833334 ,   69.416664 ,   12.341666 , 1007.4167   ],\n",
       "       [  19.125    ,   57.125    ,    7.4125   , 1012.25     ],\n",
       "       [  18.625    ,   42.875    ,   14.35     , 1015.25     ],\n",
       "       [  19.125    ,   40.375    ,   16.6625   , 1016.125    ],\n",
       "       [  19.       ,   50.42857  ,   11.928572 , 1014.2857   ],\n",
       "       [  18.75     ,   59.       ,   11.1125   , 1012.375    ],\n",
       "       [  19.875    ,   58.375    ,    5.1      , 1014.25     ],\n",
       "       [  23.333334 ,   51.666668 ,    3.911111 , 1013.1111   ],\n",
       "       [  24.461538 ,   47.923077 ,    6.415385 , 1012.9231   ],\n",
       "       [  23.75     ,   54.25     ,    5.93     , 1012.15     ],\n",
       "       [  20.5      ,   42.5      ,    7.4125   , 1010.625    ],\n",
       "       [  19.125    ,   43.125    ,    8.35     , 1010.       ],\n",
       "       [  19.75     ,   41.25     ,    9.9625   , 1010.5      ],\n",
       "       [  20.       ,   42.444443 ,    9.666667 , 1010.3333   ],\n",
       "       [  22.625    ,   41.5      ,    6.025    , 1007.375    ],\n",
       "       [  21.545454 ,   52.727272 ,   10.263637 , 1008.9091   ],\n",
       "       [  20.785715 ,   69.07143  ,    8.342857 , 1007.3571   ],\n",
       "       [  19.9375   ,   67.75     ,   11.4625   , 1006.875    ],\n",
       "       [  18.533333 ,   60.4      ,    5.5666666, 1009.8      ],\n",
       "       [  17.375    ,   56.625    ,    7.6375   , 1014.75     ],\n",
       "       [  17.444445 ,   49.333332 ,    9.055555 , 1014.8889   ],\n",
       "       [  18.       ,   56.333332 ,    4.522222 , 1016.55554  ],\n",
       "       [  19.875    ,   54.75     ,    7.175    , 1014.125    ],\n",
       "       [  24.       ,   49.2      ,    5.56     , 1011.1      ],\n",
       "       [  20.9      ,   59.7      ,   11.49     , 1010.7      ],\n",
       "       [  24.692308 ,   46.307693 ,    7.123077 , 1009.8461   ],\n",
       "       [  24.666666 ,   52.27778  ,    9.161111 , 1011.8889   ],\n",
       "       [  23.333334 ,   54.666668 ,   10.077778 , 1012.55554  ],\n",
       "       [  25.       ,   49.       ,    9.2625   , 1011.75     ],\n",
       "       [  27.25     ,   45.       ,   10.1875   , 1009.75     ],\n",
       "       [  28.       ,   49.75     ,    3.4875   , 1008.875    ],\n",
       "       [  28.916666 ,   37.666668 ,   10.033334 , 1010.5833   ],\n",
       "       [  26.5      ,   39.375    ,   10.425    , 1009.875    ],\n",
       "       [  29.1      ,   37.1      ,   17.59     , 1010.2      ],\n",
       "       [  29.5      ,   38.625    ,   13.65     , 1009.5      ],\n",
       "       [  29.88889  ,   40.666668 ,    8.844444 , 1009.       ],\n",
       "       [  31.       ,   34.5      ,   13.2      , 1007.125    ],\n",
       "       [  29.285715 ,   36.857143 ,   10.585714 , 1007.1429   ],\n",
       "       [  30.625    ,   37.625    ,    6.95     , 1007.5      ],\n",
       "       [  31.375    ,   35.125    ,    9.0375   , 1005.       ],\n",
       "       [  29.75     ,   33.75     ,    9.2625   , 1004.25     ],\n",
       "       [  30.5      ,   29.75     ,    6.9375   , 1004.25     ],\n",
       "       [  30.933332 ,   31.866667 ,   14.32     , 1007.2      ],\n",
       "       [  29.23077  ,   46.       ,   14.384615 , 1005.       ],\n",
       "       [  31.222221 ,   26.       ,   13.577778 , 1002.8889   ],\n",
       "       [  27.       ,   29.875    ,    4.65     , 1007.375    ],\n",
       "       [  25.625    ,   29.375    ,    8.3375   , 1010.375    ],\n",
       "       [  27.125    ,   21.125    ,   14.125    , 1010.625    ],\n",
       "       [  27.857143 ,   19.428572 ,   19.314285 , 1008.5714   ],\n",
       "       [  29.25     ,   17.75     ,   15.5125   , 1006.25     ],\n",
       "       [  29.25     ,   26.       ,    9.4875   , 1005.875    ],\n",
       "       [  29.666666 ,   29.11111  ,    4.9444447, 1006.7778   ],\n",
       "       [  30.5      ,   37.625    ,    1.3875   , 1004.625    ],\n",
       "       [  31.222221 ,   30.444445 ,    5.9666667, 1002.44446  ],\n",
       "       [  31.       ,   34.25     ,    2.1      , 1003.25     ],\n",
       "       [  32.555557 ,   38.444443 ,    5.366667 , 1004.44446  ],\n",
       "       [  34.       ,   27.333334 ,    7.811111 , 1003.1111   ],\n",
       "       [  33.5      ,   24.125    ,    9.025    , 1000.875    ],\n",
       "       [  34.5      ,   27.5      ,    5.5625   ,  998.625    ],\n",
       "       [  34.25     ,   39.375    ,    6.9625   ,  999.875    ],\n",
       "       [  32.9      ,   40.9      ,    8.89     , 1001.6      ],\n",
       "       [  32.875    ,   27.5      ,    9.9625   , 1002.125    ],\n",
       "       [  32.       ,   27.142857 ,   12.157143 , 1004.1429   ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the 'date' column and convert the rest to numpy\n",
    "data_test = df_test.drop(columns=['date']).values.astype(np.float32)\n",
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(columns=['date']).values.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  14.      ,   75.875   ,    2.0875  , 1021.      ],\n",
       "       [  14.375   ,   74.75    ,    5.1125  , 1018.5     ],\n",
       "       [  15.75    ,   77.125   ,    0.      , 1017.625   ],\n",
       "       ...,\n",
       "       [  14.095238,   89.666664,    6.266667, 1017.9048  ],\n",
       "       [  15.052631,   87.      ,    7.325   , 1016.1     ],\n",
       "       [  10.      ,  100.      ,    0.      , 1016.      ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[-366:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: ../models_weights_storage/seq2seq_non_autoregressive_LSTM.pth\n"
     ]
    }
   ],
   "source": [
    "# save model before eval\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# Path to save model\n",
    "model_path = os.path.join(\"../models_weights_storage\", 'seq2seq_non_autoregressive_LSTM.pth')\n",
    "\n",
    "# Save the model's state dict\n",
    "torch.save(seq2seq_model.state_dict(), model_path)\n",
    "print(f\"Model saved to: {model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample input shape:  tensor([[  14.0000,   75.8750,    2.0875, 1021.0000],\n",
      "        [  14.3750,   74.7500,    5.1125, 1018.5000],\n",
      "        [  15.7500,   77.1250,    0.0000, 1017.6250],\n",
      "        ...,\n",
      "        [  14.0952,   89.6667,    6.2667, 1017.9048],\n",
      "        [  15.0526,   87.0000,    7.3250, 1016.1000],\n",
      "        [  10.0000,  100.0000,    0.0000, 1016.0000]])\n",
      "sample input shape:  torch.Size([1, 366, 4])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Input and parameter tensors are not at the same device, found input tensor at cpu and parameter tensor at cuda:0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample input shape: \u001b[39m\u001b[38;5;124m\"\u001b[39m,sample_input\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 12\u001b[0m     predicted_output \u001b[38;5;241m=\u001b[39m \u001b[43mseq2seq_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfuture_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredicted_output:\u001b[39m\u001b[38;5;124m\"\u001b[39m, predicted_output)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Convert to numpy for plotting\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[42], line 11\u001b[0m, in \u001b[0;36mSeq2Seq.forward\u001b[0;34m(self, input_seq, target_seq_length)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_seq, target_seq_length):\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# Encoder part: obtain the hidden state from the encoder.\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# Returns a tuple (hidden_state, cell_state)\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m     encoder_hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_seq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# Prepare a non-autoregressive decoder input.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# Use the last time step from input_seq as the initial decoder input.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# For instance, use a fixed start token or learnable embeddings for each time step.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m    \n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# Here we simply repeat the last time step for all target positions.\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     decoder_input \u001b[38;5;241m=\u001b[39m input_seq[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;241m1\u001b[39m, target_seq_length, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[40], line 12\u001b[0m, in \u001b[0;36mEncoderRNN.forward\u001b[0;34m(self, input_seq)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_seq):\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# For this encoder, we ignore the outputs if we only need the final hidden state(s)\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     outputs, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_seq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:879\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    876\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[1;32m    878\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 879\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    882\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    883\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input and parameter tensors are not at the same device, found input tensor at cpu and parameter tensor at cuda:0"
     ]
    }
   ],
   "source": [
    "seq2seq_model.eval()\n",
    "future_steps = 114\n",
    "\n",
    "# Choose sample inputs from the end of the dataset\n",
    "sample_input = torch.from_numpy(df_train[-366:])\n",
    "print(\"sample input shape: \",sample_input)\n",
    "\n",
    "sample_input = sample_input.unsqueeze(0)\n",
    "print(\"sample input shape: \",sample_input.shape)\n",
    "\n",
    "with torch.no_grad():\n",
    "    predicted_output = seq2seq_model(sample_input, future_steps)\n",
    "    print(\"predicted_output:\", predicted_output)\n",
    "\n",
    "\n",
    "# Convert to numpy for plotting\n",
    "predicted_output = predicted_output.squeeze().cpu().numpy()\n",
    "grouth_truth = data_test\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "features = ['meantemp', 'humidity', 'wind_speed', 'meanpressure']\n",
    "num_features = len(features)\n",
    "time_steps = predicted_output.shape[0]  # Should be 115\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "for i in range(num_features):\n",
    "    plt.subplot(2, 2, i + 1)\n",
    "    \n",
    "    # Plot predicted vs ground truth for each feature\n",
    "    plt.plot(range(time_steps), predicted_output[:, i], label='Predicted', marker='o')\n",
    "    plt.plot(range(time_steps), grouth_truth[:, i], label='Ground Truth', marker='x', linestyle='--')\n",
    "\n",
    "    # Add labels and title using feature names\n",
    "    plt.title(f'{features[i].capitalize()}')\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel(features[i].capitalize())\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.suptitle(\"Seq2Seq Forecasting - Feature-wise Comparison\", fontsize=16, y=1.02)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
